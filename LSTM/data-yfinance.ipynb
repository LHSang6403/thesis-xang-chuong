{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pendulum\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "# Define the start and end dates for the loop\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = yf.download(\n",
    "#   tickers=['AAPL'],\n",
    "#   # start=start_time,\n",
    "#   # end=end_time,\n",
    "#   period='max',\n",
    "#   interval='1d'\n",
    "# )\n",
    "\n",
    "# # Drop second level of column names\n",
    "# data.columns = data.columns.droplevel(1)\n",
    "\n",
    "# csv_file = \"stock_data_alternative.csv\"\n",
    "# with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "# \t\twriter = csv.writer(file)\n",
    "# \t\t# Write the header\n",
    "# \t\twriter.writerow([\"Date\"] + list(data.columns))\n",
    "# \t\t# Write the data\n",
    "# \t\tfor index, row in data.iterrows():\n",
    "# \t\t\t\twriter.writerow([index] + list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    print(\"Initial data information:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Remove unnecessary columns (if there are columns named 'Unnamed')\n",
    "    df = df.loc[:, ~df.columns.get_level_values(1).str.contains('^Unnamed')]\n",
    "\n",
    "    # Handle the 'timestamp' column (if present)\n",
    "    if ('timestamp', '') in df.columns:\n",
    "        # Convert to datetime format\n",
    "        df[('timestamp', '')] = pd.to_datetime(df[('timestamp', '')], errors='coerce')  \n",
    "        \n",
    "        # Remove rows with missing timestamp values\n",
    "        df = df.dropna(subset=[('timestamp', '')]) \n",
    "\n",
    "    # Fill missing values using forward fill and backward fill methods\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    # Normalize 'close' values between 0 and 1 if present\n",
    "    if ('close', '') in df.columns:\n",
    "        df[('close', '')] = (df[('close', '')] - df[('close', '')].min()) / (df[('close', '')].max() - df[('close', '')].min())\n",
    "\n",
    "    # Print out the data after cleaning\n",
    "    print(\"Data after cleaning:\")\n",
    "    print(df.head())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "def fillData(df):\n",
    "  # Create a new DataFrame with a complete range of dates and times\n",
    "  complete_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq='1min')\n",
    "  complete_data = pd.DataFrame(index=complete_index)\n",
    "\n",
    "  # Reindex the 'all_data' DataFrame with the complete index\n",
    "  filledData = df.reindex(complete_data.index)\n",
    "\n",
    "  # Reset the index to make 'Datetime' a column again\n",
    "  filledData.reset_index(inplace=True)\n",
    "\n",
    "  # Rename the 'Datetime' column to 'index'\n",
    "  filledData.set_index('index', inplace=True)\n",
    "\n",
    "  # Rename 'index' to 'Date' in the index\n",
    "  filledData.index.name = 'Date'\n",
    "\n",
    "  # Linear interpolation to fill small gaps\n",
    "  filledData = filledData.interpolate(method='linear')\n",
    "\n",
    "  # replace nan values with mean of the before and after values for all columns\n",
    "  filledData = df.fillna(df.rolling(12, min_periods=1, center=True).mean())\n",
    "\n",
    "  # Forward and backward fill for large gaps\n",
    "  df = df.ffill().bfill()\n",
    "\n",
    "  filledData.to_csv('filledData.csv')\n",
    "\n",
    "  # for column in filledData.columns:\n",
    "  #   filledData[column] = filledData[column].fillna((filledData[column].shift() + filledData[column].shift(-1))/2)\n",
    "\n",
    "  # Print the updated DataFrame\n",
    "  # return filledData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "def UpdateData(filePath):\n",
    "\tdf = pd.DataFrame()\n",
    "\n",
    "\tdays_before = pd.Timestamp.now()\n",
    "\n",
    "\tif os.path.exists(filePath):\n",
    "\t\tdf = pd.read_csv(filePath)\n",
    "\t\t# df = pd.read_csv('./stock_data/BTC_2010-2011.csv')\n",
    "\n",
    "\t\t# Convert the 'Date' column to the DataFrame index\n",
    "\t\tdf['Date'] = pd.to_datetime(df['Date'])\n",
    "\t\tdf.set_index('Date', inplace=True)\n",
    "\t\tdays_before = df.index.max().date()\n",
    "\n",
    "\n",
    "\t# Get the end date of the data\n",
    "\tif days_before == pd.Timestamp.now():\n",
    "\t\tlast_month = pd.Timestamp.now() - pd.DateOffset(months=1)\n",
    "\t\tdays_before = last_month.date()\n",
    "\n",
    "\t# Get date time now and replace the time with 00:00:00\n",
    "\tcurrent_date = datetime.date.today()\n",
    "\n",
    "\t# Create an empty DataFrame to store the data\n",
    "\t# all_data = pd.read_csv('stock_data/BTC_2010-2011.csv', index_col=0, header=[0, 1]).sort_index(axis=1)\n",
    "\tall_data = pd.DataFrame()\n",
    "\n",
    "\tprint(days_before)\n",
    "\tprint(current_date)\n",
    "\n",
    "\t# Loop through the range of dates\n",
    "\tfor date in pd.date_range(days_before, current_date, freq='D'):\n",
    "\t\t# Define the start and end times for the data retrieval\n",
    "\t\tstart_time = date.replace(hour=0, minute=0, second=0)\n",
    "\t\tend_time = date.replace(hour=23, minute=59, second=59)\n",
    "\n",
    "\t\t# Retrieve the data for the specified date range\n",
    "\t\tdata = yf.download(\n",
    "\t\t\ttickers=['AAPL'],\n",
    "\t\t\tstart=start_time,\n",
    "\t\t\tend=end_time,\n",
    "\t\t\t# period='1d',\n",
    "\t\t\tinterval='1m'\n",
    "\t\t)\n",
    "\n",
    "\t\t# Flatten the column headers to remove the ticker\n",
    "\t\tif (isinstance(data.columns, pd.MultiIndex)):\n",
    "\t\t\t\tdata.columns = [col[0] for col in data.columns]  # Retain only the first level\n",
    "\n",
    "\t\t# Append the data to the DataFrame\n",
    "\t\tall_data = pd.concat([all_data, data])\n",
    "\t\t\n",
    "\t# Update the `all_data` to include the new data\n",
    "\tnew_data = pd.concat([df, all_data])\n",
    "\n",
    "\t# Remove any duplicate rows\n",
    "\tnew_data = new_data[~new_data.index.duplicated(keep='first')]\n",
    "\n",
    "\tnew_data.to_csv('filledData2.csv')\n",
    "\tprint(new_data)\n",
    "\n",
    "\treturn fillData(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "def splitData():\n",
    "    data = pd.read_csv('./stock_data/BTC_2010-2011.csv')\n",
    "\n",
    "    # Chuyển đổi cột 'Date' sang datetime và đặt làm index\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data.set_index('Date', inplace=True)\n",
    "\n",
    "    print(\"Các cột trong dữ liệu:\", data.columns)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    print(\"Các cột trong dữ liệu:\", data.columns)\n",
    "\n",
    "    print(data.describe())\n",
    "    print(\"Số lượng giá trị NaN trong mỗi cột:\")\n",
    "    print(data.isnull().sum())\n",
    "    print(\"Kiểm tra giá trị inf/-inf:\")\n",
    "    print(data[data.isin([np.inf, -np.inf]).any(axis=1)])\n",
    "\n",
    "    # Loại bỏ các hàng có giá trị NaN hoặc inf\n",
    "    data = data.dropna()  # Xóa hàng chứa NaN\n",
    "    data = data.replace([np.inf, -np.inf], np.nan).dropna()  # Loại bỏ inf/-inf\n",
    "\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=data.columns, index=data.index)\n",
    "    # scaled_data = pd.DataFrame(scaled_data, columns=data.columns, index=data.index)\n",
    "\n",
    "    # Số bước thời gian\n",
    "    timesteps = 100\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    close_index = data.columns.get_loc('Close')\n",
    "\n",
    "    for i in range(timesteps, len(scaled_data)):\n",
    "        X.append(scaled_data.iloc[i - timesteps:i].values)\n",
    "        y.append(scaled_data.iloc[i, close_index])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "# Function to download and format data for a single stock\n",
    "def download_and_format_stock_data(ticker, start_date, end_date, retries=3):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "            if not stock_data.empty:\n",
    "                stock_data.reset_index(inplace=True)\n",
    "                stock_data['Name'] = ticker\n",
    "                stock_data = stock_data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Name']]\n",
    "                stock_data.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'name']\n",
    "                return stock_data\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {i+1} failed for {ticker}: {e}\")\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "  # new_data = UpdateData('./stock_data/AAPL.csv')\n",
    "  UpdateData('./stock_data/AAPL.csv')\n",
    "\n",
    "  # Save the updated data to a CSV file\n",
    "  # new_data.to_csv('./stock_data/AAPL.csv')\n",
    "\n",
    "  # return splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-17\n",
      "2024-12-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-12-19 00:00:00 -> 2024-12-19 23:59:59) (Yahoo error = \"Data doesn\\'t exist for startDate = 1734584400, endDate = 1734670799\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Adj Close       Close        High         Low  \\\n",
      "2024-11-18 14:30:00+00:00  226.199997  226.199997  226.410004  225.179993   \n",
      "2024-11-18 14:31:00+00:00  226.565994  226.565994  226.639999  226.020004   \n",
      "2024-11-18 14:32:00+00:00  226.679993  226.679993  226.880005  226.430099   \n",
      "2024-11-18 14:33:00+00:00  226.410004  226.410004  226.820007  226.110001   \n",
      "2024-11-18 14:34:00+00:00  226.490005  226.490005  226.550003  226.240005   \n",
      "...                               ...         ...         ...         ...   \n",
      "2024-12-18 16:56:00+00:00  253.539902  253.539902  253.539993  253.460007   \n",
      "2024-12-18 16:57:00+00:00  253.570007  253.570007  253.570007  253.509995   \n",
      "2024-12-18 16:58:00+00:00  253.530106  253.530106  253.585007  253.520004   \n",
      "2024-12-18 16:59:00+00:00  253.430893  253.430893  253.544998  253.430099   \n",
      "2024-12-18 17:00:00+00:00  253.369995  253.369995  253.369995  253.369995   \n",
      "\n",
      "                                 Open     Volume  \n",
      "2024-11-18 14:30:00+00:00  225.199997  1331036.0  \n",
      "2024-11-18 14:31:00+00:00  226.220001   276499.0  \n",
      "2024-11-18 14:32:00+00:00  226.550003   191068.0  \n",
      "2024-11-18 14:33:00+00:00  226.750000   206426.0  \n",
      "2024-11-18 14:34:00+00:00  226.369995   131348.0  \n",
      "...                               ...        ...  \n",
      "2024-12-18 16:56:00+00:00  253.500000    35044.0  \n",
      "2024-12-18 16:57:00+00:00  253.539993    23664.0  \n",
      "2024-12-18 16:58:00+00:00  253.570007    25677.0  \n",
      "2024-12-18 16:59:00+00:00  253.544998    39454.0  \n",
      "2024-12-18 17:00:00+00:00  253.369995        0.0  \n",
      "\n",
      "[42300 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['index'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13512\\112307906.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Reset the index to make 'Datetime' a column again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Rename the 'Datetime' column to 'index'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Rename 'index' to 'Date' in the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Date'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LT MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6118\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['index'] are in the columns\""
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('filledData.csv')\n",
    "\n",
    "# Remove nan values\n",
    "df = df.dropna()\n",
    "\n",
    "# Set first column as index\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "\n",
    "# Reset the index to make 'Datetime' a column again\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the 'Datetime' column to 'index'\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "# Rename 'index' to 'Date' in the index\n",
    "df.index.name = 'Date'\n",
    "\n",
    "df.to_csv('filledData1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
