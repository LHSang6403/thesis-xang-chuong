{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students:\n",
    "\n",
    "### Le Hoang Sang\n",
    "\n",
    "### Vu Dinh Chuong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import plotly.graph_objects as go\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.base import MultiOutputMixin, RegressorMixin, BaseEstimator, _fit_context\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.utils.validation import check_is_fitted, _check_sample_weight\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from numbers import Integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    print(\"Initial data information:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Remove unnecessary columns (if there are columns named 'Unnamed')\n",
    "    df = df.loc[:, ~df.columns.get_level_values(1).str.contains('^Unnamed')]\n",
    "\n",
    "    # Handle the 'timestamp' column (if present)\n",
    "    if ('timestamp', '') in df.columns:\n",
    "        # Convert to datetime format\n",
    "        df[('timestamp', '')] = pd.to_datetime(df[('timestamp', '')], errors='coerce')  \n",
    "        \n",
    "        # Remove rows with missing timestamp values\n",
    "        df = df.dropna(subset=[('timestamp', '')]) \n",
    "\n",
    "    # Fill missing values using forward fill and backward fill methods\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    # Normalize 'close' values between 0 and 1 if present\n",
    "    if ('close', '') in df.columns:\n",
    "        df[('close', '')] = (df[('close', '')] - df[('close', '')].min()) / (df[('close', '')].max() - df[('close', '')].min())\n",
    "\n",
    "    # Print out the data after cleaning\n",
    "    print(\"Data after cleaning:\")\n",
    "    print(df.head())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain forward fill and backward fill methods\n",
    "\n",
    "#### FFill\n",
    "data = [1, 2, NaN, NaN, 5]\n",
    "\n",
    "filled_data = [1, 2, 2, 2, 5]\n",
    "\n",
    "=> 'NaN' values replaced with the previous valid value (2).\n",
    "\n",
    "#### BFill\n",
    "data = [1, 2, NaN, NaN, 5]\n",
    "\n",
    "filled_data = [1, 2, 5, 5, 5]\n",
    "\n",
    "=>'NaN' values replaced with the next valid value (5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain Min-max Normalization\n",
    "\n",
    "normalized_value= (max_value ‚àí min_value) / (original_value ‚àí min_value)\n",
    "\n",
    "‚Äã\n",
    "Example:\n",
    "\n",
    "close = [50, 55, 60, 65, 70]\n",
    "\n",
    "min(x)=50\n",
    "max(ùë•)=70\n",
    "\n",
    "With value 60:\n",
    "x_normalized = (60‚àí50) / (70‚àí50) = 10 / 20 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the DataFrame: The dataset we re working with a MultiIndex data structure, where the first level of the index (such as 'A', 'AAL', etc.) represents the stock symbol, and the second level represents the attributes of the stock (such as 'close', 'open', 'high', etc.).\n",
    "\n",
    "'A' is a stock symbol representing a specific company or asset.\n",
    "\n",
    "Other symbols like 'AAL', 'ZION', etc., represent different companies or assets.\n",
    "\n",
    "Why set symbol = 'A'?\n",
    "\n",
    "In our code, setting symbol = 'A' focuses on the data of a specific company or asset. \n",
    "\n",
    "Since our DataFrame contains data for multiple stock symbols, we need to specify which stock symbol we want to use for feature generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df_features = df.copy()\n",
    "\n",
    "    print(\"Column names in the DataFrame:\", df_features.columns)\n",
    "\n",
    "    # Define the symbol you want to work with (e.g., 'A', 'AAL', etc.)\n",
    "    symbol = 'A'\n",
    "\n",
    "    # Define the columns for the selected stock symbol\n",
    "    numeric_cols = [(symbol, 'open'), (symbol, 'high'), (symbol, 'low'), (symbol, 'close'), (symbol, 'volume')]\n",
    "\n",
    "    # Check if these columns exist in the DataFrame\n",
    "    existing_cols = [col for col in numeric_cols if col in df_features.columns]\n",
    "\n",
    "    if not existing_cols:\n",
    "        raise ValueError(\"Required numeric columns not found in the DataFrame.\")\n",
    "\n",
    "    # Convert the necessary columns to numeric type\n",
    "    df_features[existing_cols] = df_features[existing_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Remove rows with NaN values after conversion\n",
    "    df_features = df_features.dropna()\n",
    "\n",
    "    # Create features if the necessary columns exist\n",
    "    if (symbol, 'close') in df_features.columns:\n",
    "        df_features[(symbol, 'return')] = df_features[(symbol, 'close')].pct_change()\n",
    "        df_features[(symbol, 'ma7')] = df_features[(symbol, 'close')].rolling(window=7).mean()\n",
    "        df_features[(symbol, 'ma21')] = df_features[(symbol, 'close')].rolling(window=21).mean()\n",
    "        df_features[(symbol, 'volatility')] = df_features[(symbol, 'close')].rolling(window=7).std()\n",
    "    \n",
    "    if (symbol, 'open') in df_features.columns and (symbol, 'close') in df_features.columns:\n",
    "        df_features[(symbol, 'open_close_ratio')] = df_features[(symbol, 'open')] / df_features[(symbol, 'close')]\n",
    "    \n",
    "    if (symbol, 'high') in df_features.columns and (symbol, 'low') in df_features.columns:\n",
    "        df_features[(symbol, 'high_low_ratio')] = df_features[(symbol, 'high')] / df_features[(symbol, 'low')]\n",
    "\n",
    "    # Remove rows with NaN values due to calculations\n",
    "    df_features = df_features.dropna()  \n",
    "\n",
    "    print(\"DataFrame with new features:\")\n",
    "    print(df_features.head())\n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(df_features, symbol='A'):\n",
    "    # Ensure symbol exists in the DataFrame\n",
    "    if symbol not in df_features.columns.get_level_values(0):\n",
    "        raise ValueError(f\"Symbol '{symbol}' not found in DataFrame columns.\")\n",
    "\n",
    "    # Plot the 'close' price\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(df_features.index, df_features[(symbol, 'close')], label=f'{symbol} Close Price', color='b')\n",
    "    plt.title(f'{symbol} Close Price Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the 7-day and 21-day moving averages\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(df_features.index, df_features[(symbol, 'ma7')], label=f'{symbol} MA7', color='g')\n",
    "    plt.plot(df_features.index, df_features[(symbol, 'ma21')], label=f'{symbol} MA21', color='r')\n",
    "    plt.title(f'{symbol} 7-day and 21-day Moving Averages')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the open/close ratio\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(df_features.index, df_features[(symbol, 'open_close_ratio')], label=f'{symbol} Open/Close Ratio', color='orange')\n",
    "    plt.title(f'{symbol} Open/Close Ratio Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Ratio')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the high/low ratio\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(df_features.index, df_features[(symbol, 'high_low_ratio')], label=f'{symbol} High/Low Ratio', color='brown')\n",
    "    plt.title(f'{symbol} High/Low Ratio Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Ratio')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv', index_col=0, header=[0, 1]).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = clean_data(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 6 first columns\n",
    "df_features = create_features(df_cleaned.iloc[:, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for the symbol 'A'\n",
    "df1 = df_features.loc[:, 'A']\n",
    "# Get first 6 columns\n",
    "df1 = df1.iloc[:, :5]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock symbol 'A' behaviour\n",
    "df1.plot(subplots=True, figsize=(15, 15))\n",
    "plt.suptitle('A stock attributes from 24/01/2014 to 25/06/2021', y=0.91)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train from  11/09/2017 9:30 A.M. to 17/01/2018 11:50 A.M and test data  from 17/01/2018 11:51A.M. to 16/02/2018 03:59A.M\n",
    "train = df1.loc['2017-11-12 09:30:00':'2018-01-30 11:50:00']\n",
    "test = df1.loc['2018-01-30 11:51:00':'2018-02-16 03:59:00']\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "# Create a function to create sequences of data\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences with a length of 10\n",
    "seq_length = 11\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "\n",
    "# Create data loaders\n",
    "train_data = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).float())\n",
    "test_data = TensorDataset(torch.tensor(X_test).float(), torch.from_numpy(y_test).float())\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class VanillaLSTM(nn.Module):\n",
    "    def __init__(self, num_feature):\n",
    "        super(VanillaLSTM, self).__init__()\n",
    "        self.lstm  = nn.LSTM(num_feature,64,batch_first=True)\n",
    "        self.fc    = nn.Linear(64,num_feature)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (hidden, cell) = self.lstm(x)\n",
    "        x = self.fc(hidden)\n",
    "        return x\n",
    "\n",
    "model = VanillaLSTM(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optiemizer and rmse loss function\n",
    "import torch.optim as optim\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "\n",
    "criterion = RMSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    epoch_loss = 0\n",
    "    model.train()  \n",
    "    \n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()          \n",
    "        x,y = batch\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred[0],y)        \n",
    "        loss.backward()               \n",
    "        optimizer.step()      \n",
    "        epoch_loss += loss.item()  \n",
    "        \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    epoch_loss = 0\n",
    "    model.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "      for batch in dataloader:   \n",
    "          x,y= batch\n",
    "          pred = model(x)\n",
    "          loss = criterion(pred[0],y)              \n",
    "          epoch_loss += loss.item()  \n",
    "        \n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 600\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = train(train_loader)\n",
    "    valid_loss = evaluate(test_loader)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model, './checkpoint/saved_weights.pt')\n",
    "\n",
    "    if (epoch % 200 == 0):\n",
    "        print(f'\\tEpoch: {epoch} | ' + f'\\tTrain Loss: {train_loss:.5f} | ' + f'\\tVal Loss: {valid_loss:.5f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('./checkpoint/saved_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X_test).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "  y_test_pred = model(X_test)\n",
    "\n",
    "y_test_pred = y_test_pred.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_test_pred, multioutput='raw_values'))\n",
    "mse = mean_squared_error(y_test, y_test_pred, multioutput='raw_values')\n",
    "mae = mean_absolute_error(y_test, y_test_pred, multioutput='raw_values')\n",
    "r2 = r2_score(y_test, y_test_pred, multioutput='raw_values')\n",
    "index = ['RMSE','MSE', 'MAE', 'R2 score']\n",
    "\n",
    "results = pd.DataFrame([rmse, mse, mae, r2], index=index, columns=['close','high','low','open','volume'])\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = df1.loc['2017-11-12 09:30:00':'2018-01-30 11:50:00'] \n",
    "\n",
    "test = df1.loc['2018-01-30 11:51:00':'2018-02-16 03:59:00']\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>close</th>\n",
    "      <th>high</th>\n",
    "      <th>low</th>\n",
    "      <th>open</th>\n",
    "      <th>volume</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>RMSE</th>\n",
    "      <td>0.045912</td>\n",
    "      <td>0.043599</td>\n",
    "      <td>0.044478</td>\n",
    "      <td>0.040182</td>\n",
    "      <td>0.671828</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>MSE</th>\n",
    "      <td>0.002108</td>\n",
    "      <td>0.001901</td>\n",
    "      <td>0.001978</td>\n",
    "      <td>0.001615</td>\n",
    "      <td>0.451353</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>MAE</th>\n",
    "      <td>0.024092</td>\n",
    "      <td>0.018686</td>\n",
    "      <td>0.021166</td>\n",
    "      <td>0.014628</td>\n",
    "      <td>0.253309</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>R2 score</th>\n",
    "      <td>0.998083</td>\n",
    "      <td>0.998259</td>\n",
    "      <td>0.998214</td>\n",
    "      <td>0.998533</td>\n",
    "      <td>0.272340</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=5)\n",
    "fig.set_figwidth(25)\n",
    "fig.set_figheight(5)\n",
    "for i in range(5):\n",
    "    ax[i].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,i], color='black', label='test target')\n",
    "\n",
    "    ax[i].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,i], color='red', label='test prediction')\n",
    "\n",
    "    ax[i].set_xlabel('time [days]')\n",
    "    ax[i].set_ylabel('price')\n",
    "    ax[i].legend(loc='best')\n",
    "\n",
    "ax[0].set_title('future close prices')\n",
    "ax[1].set_title('future high prices')\n",
    "ax[2].set_title('future low prices')\n",
    "ax[3].set_title('future open prices')\n",
    "ax[4].set_title('future volume prices')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,5) (10,) (10,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m pred_mins \u001b[38;5;241m=\u001b[39m last_sequence\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# inverse transform the predicted values\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m pred_mins \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_mins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m df_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     26\u001b[0m     data\u001b[38;5;241m=\u001b[39mpred_mins,\n\u001b[0;32m     27\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Open>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<High>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Low>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Close>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Volume>\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m df_pred\n",
      "File \u001b[1;32mc:\\Users\\LT MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1064\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1064\u001b[0m         \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_\u001b[49m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1066\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,5) (10,) (10,5) "
     ]
    }
   ],
   "source": [
    "# Predicting the next 1 mins\n",
    "seq_len = 11\n",
    "sequences = []\n",
    "for index in range(len(test) - seq_len + 1): \n",
    "    sequences.append(test[index: index + seq_len])\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "last_sequence = sequences[-1:, 1:, :]\n",
    "last_sequence = torch.from_numpy(last_sequence).float()\n",
    "\n",
    "# Generate predictions\n",
    "PREDICT = 1\n",
    "with torch.no_grad():\n",
    "    for i in range(PREDICT):\n",
    "        pred_i = model(last_sequence)\n",
    "        last_sequence = torch.cat((last_sequence, pred_i), dim=1)\n",
    "        last_sequence = last_sequence[:, 1:, :]\n",
    "\n",
    "pred_mins = last_sequence.squeeze(0).numpy()\n",
    "\n",
    "# inverse transform the predicted values\n",
    "pred_mins = scaler.inverse_transform(pred_mins)\n",
    "\n",
    "df_pred = pd.DataFrame(\n",
    "    data=pred_mins,\n",
    "    columns=['<Open>', '<High>', '<Low>', '<Close>', '<Volume>']\n",
    ")\n",
    "\n",
    "print(def_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,5) (10,) (10,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m pred_mins \u001b[38;5;241m=\u001b[39m last_sequence\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# inverse transform the predicted values\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m pred_mins \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_mins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m df_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     26\u001b[0m     data\u001b[38;5;241m=\u001b[39mpred_mins,\n\u001b[0;32m     27\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Open>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<High>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Low>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Close>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Volume>\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     28\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LT MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1064\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1064\u001b[0m         \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_\u001b[49m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1066\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,5) (10,) (10,5) "
     ]
    }
   ],
   "source": [
    "# Predicting the next 5 mins\n",
    "\n",
    "seq_len = 11\n",
    "sequences = []\n",
    "for index in range(len(test) - seq_len + 1): \n",
    "    sequences.append(test[index: index + seq_len])\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "last_sequence = sequences[-1:, 1:, :]\n",
    "last_sequence = torch.from_numpy(last_sequence).float()\n",
    "\n",
    "# Generate predictions\n",
    "PREDICT = 5\n",
    "with torch.no_grad():\n",
    "    for i in range(PREDICT):\n",
    "        pred_i = model(last_sequence)\n",
    "        last_sequence = torch.cat((last_sequence, pred_i), dim=1)\n",
    "        last_sequence = last_sequence[:, 1:, :]\n",
    "\n",
    "pred_mins = last_sequence.squeeze(0).numpy()\n",
    "\n",
    "# inverse transform the predicted values\n",
    "pred_mins = scaler.inverse_transform(pred_mins)\n",
    "\n",
    "df_pred = pd.DataFrame(\n",
    "    data=pred_mins,\n",
    "    columns=['<Open>', '<High>', '<Low>', '<Close>', '<Volume>']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,5) (10,) (10,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m pred_mins \u001b[38;5;241m=\u001b[39m last_sequence\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# inverse transform the predicted values\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m pred_days \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_days\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m df_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     26\u001b[0m     data\u001b[38;5;241m=\u001b[39mpred_days,\n\u001b[0;32m     27\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Open>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<High>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Low>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Close>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Volume>\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     28\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LT MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1064\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1064\u001b[0m         \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_\u001b[49m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1066\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,5) (10,) (10,5) "
     ]
    }
   ],
   "source": [
    "# Predicting the next 10 mins\n",
    "\n",
    "seq_len = 11\n",
    "sequences = []\n",
    "for index in range(len(test) - seq_len + 1): \n",
    "    sequences.append(test[index: index + seq_len])\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "last_sequence = sequences[-1:, 1:, :]\n",
    "last_sequence = torch.from_numpy(last_sequence).float()\n",
    "\n",
    "# Generate predictions\n",
    "PREDICT = 10\n",
    "with torch.no_grad():\n",
    "    for i in range(PREDICT):\n",
    "        pred_i = model(last_sequence)\n",
    "        last_sequence = torch.cat((last_sequence, pred_i), dim=1)\n",
    "        last_sequence = last_sequence[:, 1:, :]\n",
    "\n",
    "pred_mins = last_sequence.squeeze(0).numpy()\n",
    "\n",
    "# inverse transform the predicted values\n",
    "pred_mins = scaler.inverse_transform(pred_mins)\n",
    "\n",
    "df_pred = pd.DataFrame(\n",
    "    data=pred_mins,\n",
    "    columns=['<Open>', '<High>', '<Low>', '<Close>', '<Volume>']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features = create_features(df_cleaned)\n",
    "\n",
    "# print('features', df_features.head())\n",
    "\n",
    "# plot_features(df_features, symbol='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Feature and technical indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add EMA12, EMA25, MACD, Boillinger Up and Boillinger Down to df2 dataframe\n",
    "df2 = df_features.loc[:, 'A']\n",
    "df2 = df2.iloc[:, :5]\n",
    "df2['EMA12'] = df2['close'].ewm(span=12, adjust=False).mean()\n",
    "df2['EMA26'] = df2['close'].ewm(span=26, adjust=False).mean()\n",
    "df2['MACD'] = df2['EMA12'] - df2['EMA26']\n",
    "df2['Boillinger Up'] = df2['close'].rolling(window=20).mean() + 2*df2['close'].rolling(window=20).std()\n",
    "df2['Boillinger Down'] = df2['close'].rolling(window=20).mean() - 2*df2['close'].rolling(window=20).std()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = df2.loc['2017-11-12 09:30:00':'2018-01-30 11:50:00']\n",
    "test2 = df2.loc['2018-01-30 11:51:00':'2018-02-16 03:59:00']\n",
    "# Standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_scaled2 = scaler.fit_transform(train2)\n",
    "test_scaled2 = scaler.transform(test2)\n",
    "\n",
    "# Create a function to create sequences of data\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences with a length of 10\n",
    "seq_length = 11\n",
    "X_train2, y_train2 = create_sequences(train_scaled2, seq_length)\n",
    "X_test2, y_test2 = create_sequences(test_scaled2, seq_length)\n",
    "\n",
    "# Create data loaders\n",
    "train_data2 = TensorDataset(torch.tensor(X_train2).float(), torch.tensor(y_train2).float())\n",
    "test_data2 = TensorDataset(torch.tensor(X_test2).float(), torch.from_numpy(y_test2).float())\n",
    "\n",
    "batch_size = 64\n",
    "train_loader2 = DataLoader(train_data2, shuffle=True, batch_size=batch_size)\n",
    "test_loader2 = DataLoader(test_data2, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 600\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = train(train_loader2)\n",
    "    valid_loss = evaluate(test_loader2)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model, './checkpoint/saved_weights2.pt')\n",
    "\n",
    "    if (epoch % 200 == 0):\n",
    "        print(f'\\tEpoch: {epoch} | ' + f'\\tTrain Loss: {train_loss:.5f} | ' + f'\\tVal Loss: {valid_loss:.5f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('./checkpoint/saved_weights2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = torch.tensor(X_test2).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "  y_test_pred2 = model(X_test2)\n",
    "  \n",
    "y_test_pred2 = y_test_pred2.numpy()[0]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test2, y_test_pred2, multioutput='raw_values'))\n",
    "mse = mean_squared_error(y_test2, y_test_pred2, multioutput='raw_values')\n",
    "mae = mean_absolute_error(y_test2, y_test_pred2, multioutput='raw_values')\n",
    "r2 = r2_score(y_test2, y_test_pred2, multioutput='raw_values')\n",
    "index = ['RMSE','MSE', 'MAE', 'R2 score']\n",
    "\n",
    "results = pd.DataFrame([rmse, mse, mae, r2], index=index, columns=['close','high','low','open','volume', 'EMA12', 'EMA26', 'MACD', 'Boillinger Up', 'Boillinger Down'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=5)\n",
    "fig.set_figwidth(25)\n",
    "fig.set_figheight(5)\n",
    "for i in range(5):\n",
    "    ax[i].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,i], color='black', label='test target')\n",
    "\n",
    "    ax[i].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,i], color='red', label='test prediction')\n",
    "\n",
    "    ax[i].set_xlabel('time [days]')\n",
    "    ax[i].set_ylabel('price')\n",
    "    ax[i].legend(loc='best')\n",
    "\n",
    "ax[0].set_title('future close prices')\n",
    "ax[1].set_title('future high prices')\n",
    "ax[2].set_title('future low prices')\n",
    "ax[3].set_title('future open prices')\n",
    "ax[4].set_title('future volume prices')\n",
    "\n",
    "# Show EMA12, EMA25, MACD, Boillinger Up and Boillinger Down base one the close price\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5)\n",
    "fig.set_figwidth(25)\n",
    "fig.set_figheight(5)\n",
    "\n",
    "ax[0].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "          y_test[:,5], color='black', label='test target')\n",
    "\n",
    "ax[0].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test_pred.shape[0]),\n",
    "          y_test_pred[:,5], color='red', label='test prediction')\n",
    "\n",
    "ax[0].set_xlabel('time [days]')\n",
    "ax[0].set_ylabel('price')\n",
    "ax[0].legend(loc='best')\n",
    "ax[0].set_title('future EMA12 prices')\n",
    "\n",
    "ax[1].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "          y_test[:,6], color='black', label='test target')\n",
    "\n",
    "ax[1].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test_pred.shape[0]),\n",
    "          y_test_pred[:,6], color='red', label='test prediction')\n",
    "\n",
    "ax[1].set_xlabel('time [days]')\n",
    "ax[1].set_ylabel('price')\n",
    "ax[1].legend(loc='best')\n",
    "ax[1].set_title('future EMA26 prices')\n",
    "\n",
    "ax[2].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "          y_test[:,7], color='black', label='test target')  \n",
    "ax[2].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test_pred.shape[0]), \n",
    "          y_test_pred[:,7], color='red', label='test prediction')\n",
    "ax[2].set_xlabel('time [days]') \n",
    "ax[2].set_ylabel('price')\n",
    "ax[2].legend(loc='best')\n",
    "ax[2].set_title('future MACD prices')\n",
    "\n",
    "ax[3].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "          y_test[:,8], color='black', label='test target')\n",
    "ax[3].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test_pred.shape[0]),\n",
    "          y_test_pred[:,8], color='red', label='test prediction')\n",
    "ax[3].set_xlabel('time [days]')\n",
    "ax[3].set_ylabel('price')\n",
    "ax[3].legend(loc='best')\n",
    "ax[3].set_title('future Boillinger Up prices')\n",
    "\n",
    "ax[4].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "          y_test[:,9], color='black', label='test target')\n",
    "ax[4].plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test_pred.shape[0]),  \n",
    "          y_test_pred[:,9], color='red', label='test prediction')\n",
    "ax[4].set_xlabel('time [days]')\n",
    "ax[4].set_ylabel('price') \n",
    "ax[4].legend(loc='best')\n",
    "ax[4].set_title('future Boillinger Down prices')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the next 10 mins\n",
    "seq_len = 11\n",
    "sequences = []\n",
    "for index in range(len(test) - seq_len + 1): \n",
    "    sequences.append(test[index: index + seq_len])\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "last_sequence = sequences[-1:, 1:, :]\n",
    "last_sequence = torch.from_numpy(last_sequence).float()\n",
    "\n",
    "# Generate predictions\n",
    "PREDICT = 10\n",
    "with torch.no_grad():\n",
    "    for i in range(PREDICT):\n",
    "        pred_i = model(last_sequence)\n",
    "        last_sequence = torch.cat((last_sequence, pred_i), dim=1)\n",
    "        last_sequence = last_sequence[:, 1:, :]\n",
    "\n",
    "pred_mins = last_sequence.squeeze(0).numpy()\n",
    "\n",
    "# inverse transform the predicted values\n",
    "pred_mins = scaler.inverse_transform(pred_mins)\n",
    "\n",
    "df_pred = pd.DataFrame(\n",
    "    data=pred_mins,\n",
    "    columns=['<Open>', '<High>', '<Low>', '<Close>', '<Volume>', '<EMA12>', '<EMA26>', '<MACD>', '<Boillinger Up>', '<Boillinger Down>']\n",
    ")\n",
    "\n",
    "print(def_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
